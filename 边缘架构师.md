# 边缘架构师入门必知

## 边缘位置的约束是什么?
边缘运营不能简单地复制数据中心的脚本。 

例如，边缘集群可能安装在没有IT人员的地方，甚至可能安装在根本没有人员存在的地方。这可能需要从不同的角度考虑物理安全性，因为任何人都可以访问硬件。或者，可能会导致采用不同的策略来处理硬件故障，而不是在24小时有IT人员覆盖的数据中心中遵循的策略。 

还可能要处理潜在的不可靠和吞吐量受限的网络。在数据中心中，通常可以将高带宽和低延迟网络连接(尤其是在数据中心内)作为给定条件。在边缘架构中则不是这样。 

希望边缘系统具有高可用性吗？是否希望在尺寸和功率方面最小化其成本和占用空间？如果边缘集群失去了连接，想怎么做？想要一种即使在降级模式下也能继续运行的方法吗？需要与数据中心通信的次数和频率是多少？

对这些问题的回答可能会导致截然不同的架构决策。(考虑到边缘部署可以扩展到数以万计的节点，这将大大改变价格和成本——即使是很小的单个成本差异也会产生重大影响。)


## 让我们更多地谈谈数据
到目前为止，数据基本上是我们故事中隐含的一部分。然而，我想把它提升一个层次，因为数据在边缘计算方面扮演着如此重要的角色。如果没有数据，我们基本上不会有或者需要边缘计算，也许只是一些传感器向中心位置报告。 

数据是洞察的来源。边缘设备从传感器、可穿戴设备和其他来源收集和预处理数据，为实时洞察和决策提供原材料。边缘系统还可以过滤和预处理数据，并将其发送回更大的集中式系统以供进一步使用和分析。一种常见的架构是在数据中心开发AI/ML模型，通常由GPU和其他专用硬件辅助，然后定期将训练好的模型部署回边缘系统。 

边缘的数据分析还可以触发即时行动，例如根据传感器读数调整工业机械设置或根据实时拥堵数据路由流量。在红帽零售边缘解决方案中，可以看到来自边缘设备的数据如何传输到红帽AMQ，以便在核心数据中心进行模型开发，并在商店中进行实时推断。Apache Camel K提供传感器数据到其他组件的集成、规范化和路由。传感器数据被镜像到IBM Storage Ceph提供的数据湖中。


## 考虑大规模运营
边缘计算面临的许多最紧迫的挑战与规模有关；可能有数千个(或更多)网络端点。必须实现标准化，让操作面积最小化，甚至是最小的事情也要自动化。 

应该选择原子化更新，这样边缘系统就不会只进行部分更新，从而处于定义不清的状态。与其从集中位置推送更新，不如考虑尽可能从边缘位置拉出更新；这使得边缘设备可以根据其特定需求和网络条件选择更新的时间和频率。但是，无论确切的更新过程是什么，都要注意通过间隔更新过程来避免系统和网络过载。 

红帽Ansible自动化平台使用容器化和自动化来帮助运维团队标准化配置和部署，一直到边缘位置。它提供了IT环境的单一、一致的视图，因此团队可以可靠地管理数千个站点、网络设备和集群。 

开发自动化策略是开发边缘架构的关键部分。

## 适应性

自20世纪90年代末开始出现各种形式的边缘计算以来，它已经发展和自适应了。(内容交付网络通常被认为是一个先驱。)它的发展源于围绕分布式计算、减少延迟和更接近源处理数据的技术和需求的融合。 

边缘计算架构通常变得更加复杂，具有更多的层。 

作为5G部署的一部分，我们看到运营商正在转向更灵活的vRAN方法，通过将硬件和软件解耦来分解高级逻辑RAN组件，并使用云技术进行自动部署、扩展和工作负载放置。 

我们今天看到的一个重大变化是，边缘上有更多的计算和更多的存储。分散式系统的存在往往是为了减少对网络链接的依赖，而不是为了执行在中心位置(假设有合理的通信链接)实际上无法完成的任务。AI/ML确保了不可能将所有数据发送回家，然后等待分析结果。 

当然，这使得架构师的工作更加困难。但这也为他们帮助组织实现目标提供了可能性。 